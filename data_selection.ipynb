{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "repo_path = 'datasets/data_repo/data_repo_duplicate_removed.json'\n",
    "\n",
    "with open(repo_path, 'r') as f:\n",
    "    data_repo = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sims(path):\n",
    "    sims = torch.load(path, map_location=torch.device('cpu'))\n",
    "    return sims\n",
    "\n",
    "def get_sims(i, data, cato_size=3, num_idx=50000):\n",
    "    sims = data[:, i*cato_size:(i+1)*cato_size]\n",
    "    \n",
    "    sims = torch.mean(sims, dim=1)\n",
    "    # sims = data[:, i]\n",
    "    _, idx = torch.topk(sims, num_idx)\n",
    "    idx = idx.cpu().tolist()\n",
    "    # print(idx[:20])\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(sims, num, type_num=23, cato_size=3):\n",
    "    idx_return = []\n",
    "    num_cur = num // type_num\n",
    "    while len(idx_return) < num:\n",
    "        for i in range(type_num):\n",
    "            idx = get_sims(i, sims, cato_size=cato_size, num_idx=num_cur)\n",
    "            idx_return.extend(idx[:num_cur])\n",
    "        idx_return = list(set(idx_return))\n",
    "        if len(idx_return) > num:\n",
    "            # print(\"idx stop:\", num_cur)\n",
    "            idx_return = idx_return[:num]\n",
    "            break\n",
    "        else:\n",
    "            num_cur += max((num - len(idx_return)) // type_num, 1)\n",
    "            idx_return = []\n",
    "    idx_return = idx_return[:num]\n",
    "    return idx_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_total(sims_total, type_num=23, cato_size=3, num_sims=13534):\n",
    "    from tqdm import tqdm\n",
    "    idx_mean_total = []\n",
    "    idx_iso_total = []\n",
    "    for sims in tqdm(sims_total):\n",
    "        sims_mean = torch.mean(sims, dim=-1)\n",
    "        _, idx = torch.topk(sims_mean, num_sims)\n",
    "        idx_mean_total.append(idx.cpu().tolist())\n",
    "        idx_iso = get_index(sims, num_sims, type_num=type_num, cato_size=cato_size)\n",
    "        idx_iso_total.append(idx_iso)\n",
    "    return idx_mean_total, idx_iso_total\n",
    "\n",
    "def get_mixed_idx(sims_base_total, sims_diff_total, num_sims=13534, type_num=46, cato_size=3):\n",
    "    from tqdm import tqdm\n",
    "    mixed_idx = []\n",
    "    for sims_baes, sims_diff in tqdm(zip(sims_base_total, sims_diff_total)):\n",
    "        sims_total = torch.cat([sims_baes, sims_diff], dim=-1)\n",
    "        idx_mix = get_index(sims_total, num_sims, type_num=type_num, cato_size=cato_size)\n",
    "        mixed_idx.append(idx_mix)\n",
    "    return mixed_idx\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tydiqa_15_cluster_llama_1.json\n"
     ]
    }
   ],
   "source": [
    "name_list = []\n",
    "def save_file(idx, start, path):\n",
    "    data_sampled = []\n",
    "    import random\n",
    "    from tqdm import tqdm\n",
    "    for id in idx:\n",
    "        data_sampled.append(data_repo[id])\n",
    "    random.seed(42)\n",
    "    random.shuffle(data_sampled)\n",
    "    save_path = path.format(start)\n",
    "\n",
    "    with open(save_path, 'w') as f:\n",
    "        json.dump(data_sampled, f, indent=4, ensure_ascii=False)\n",
    "    print(save_path.split('/')[-1])\n",
    "    name_list.append(save_path.split('/')[-1])\n",
    "\n",
    "path_format = 'data_selections/tydiqa_{}_cluster_llama_1.json'\n",
    "j = 15\n",
    "for idx in idx_mean_total_diff:\n",
    "    save_file(idx, j, path_format)\n",
    "    j += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-factory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
